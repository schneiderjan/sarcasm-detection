{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm classification: BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, f1_score, precision_recall_curve,average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set properties for reading dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_file = \"data/tweets_all.csv\"\n",
    "names=['tweetID','tweet', 'target','pos','neu','neg','caps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(date_file, delimiter='|', encoding=\"utf-8\", quotechar='\"', header=None, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove and convert objects to numeric values and drop NA's (only around 10 are being dropped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>caps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500370339566985216</td>\n",
       "      <td>Zo fijn die #PostNL beloofd eerst tm vanmorgen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>411900187649794048</td>\n",
       "      <td>Heel fijn Vast op Dordrecht geen treinverkeer ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175627549802639361</td>\n",
       "      <td>echt geweldig blyk denk dat ik dan maar weer v...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321699315707936769</td>\n",
       "      <td>fijn een product hebben dat niet werkt #kpn</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258575794601865217</td>\n",
       "      <td>lekker chatten met een medewerker van tmobile</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetID                                              tweet  \\\n",
       "0  500370339566985216  Zo fijn die #PostNL beloofd eerst tm vanmorgen...   \n",
       "1  411900187649794048  Heel fijn Vast op Dordrecht geen treinverkeer ...   \n",
       "2  175627549802639361  echt geweldig blyk denk dat ik dan maar weer v...   \n",
       "3  321699315707936769        fijn een product hebben dat niet werkt #kpn   \n",
       "4  258575794601865217     lekker chatten met een medewerker van tmobile    \n",
       "\n",
       "   target    pos    neu    neg  caps  \n",
       "0       1  0.091  0.909  0.000     0  \n",
       "1       1  0.114  0.762  0.124     0  \n",
       "2       1  0.186  0.814  0.000     0  \n",
       "3       1  0.184  0.816  0.000     0  \n",
       "4       1  0.327  0.673  0.000     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df[\"target\"] = df[\"target\"].convert_objects(convert_numeric=True)\n",
    "\n",
    "df = df.dropna()\n",
    "df[\"target\"] = df[\"target\"].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(df[['tweet','pos','neu','neg','caps']]\n",
    ", df['target'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer and extractor classes, which are needed to extract data out of the df and transform into the right shape so they are ready to be used by the feature union (FU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.columns]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reshaper(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.reshape((len(X), 1))\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is a mix out of the FU and nested pipelines inside a pipeline. Inside the FU features are extracted using the transformer and extractor classes. The tweets are being processed using the CountVectorizer and TfidfTransformer. Afterwards, using SelectKbest with chi2, best features are selected and passed to the classifier (BernoulliNB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pos', Pipeline(steps=[('extract', <__main__.ColumnExtractor object at 0x0000000008C2AAC8>), ('to_dense', <__main__.Reshaper object at 0x0000000008C2AB00>)])), ('neu', Pipeline(steps=[('extract', <__main__.ColumnExtractor object at...r_weights=None)), ('clf', BernoulliNB(alpha=1e-05, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', FeatureUnion\n",
    "     ([      \n",
    "        ('pos', Pipeline([\n",
    "            ('extract', ColumnExtractor('pos')),\n",
    "            ('to_dense', Reshaper())\n",
    "        ])),\n",
    "        ('neu', Pipeline([\n",
    "            ('extract', ColumnExtractor('neu')),\n",
    "            ('to_dense', Reshaper())\n",
    "        ])),\n",
    "        ('neg', Pipeline([\n",
    "            ('extract', ColumnExtractor('neg')),\n",
    "            ('to_dense', Reshaper())\n",
    "        ])),\n",
    "        ('tweet', Pipeline([\n",
    "            ('extract', ColumnExtractor('tweet')),\n",
    "            ('vect', CountVectorizer(ngram_range=(1, 3), max_df=0.3, min_df=0.0001, max_features=10000)),\n",
    "            ('tfidf', TfidfTransformer(sublinear_tf= True, use_idf=False)),\n",
    "            (\"kbest\", SelectKBest(chi2,k=650))\n",
    "            ]))      \n",
    "        ])),\n",
    "        ('clf', BernoulliNB(alpha=1e-05))])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.49224506e-01   1.50775494e-01]\n",
      " [  9.33564321e-01   6.64356795e-02]\n",
      " [  9.33564321e-01   6.64356795e-02]\n",
      " ..., \n",
      " [  5.81542542e-01   4.18457458e-01]\n",
      " [  3.79453652e-01   6.20546348e-01]\n",
      " [  9.99861306e-01   1.38693880e-04]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_pred_proba = pipe.predict_proba(X_test)\n",
    "print(y_pred_proba )\n",
    "#predict proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the classification. Precision and Recall is calculated and their respective F1 score, as well as a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.759002770083\n",
      "Recall: 0.754820936639\n",
      "F1 score: 0.756906077348\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "   S    -S\n",
      " S TP   FN\n",
      "-S FP   TN\n",
      "[[293  87]\n",
      " [ 89 274]]\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=None)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: \"+str(precision))\n",
    "print(\"Recall: \"+str(recall))\n",
    "print(\"F1 score: \"+str(f1))\n",
    "print(\"\\nConfusion matrix: \")\n",
    "print(\"\\n   S    -S\")\n",
    "print(\" S TP   FN\")\n",
    "print(\"-S FP   TN\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.48855989  0.75900277  1.        ] [ 1.          0.75482094  0.        ] [0 1]\n",
      "0.816804181759\n"
     ]
    }
   ],
   "source": [
    "precision_curve, recall_curve, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "precision_plot, recall_plot,_ = precision_recall_curve(y_test.ravel(), y_pred.ravel())\n",
    "print(precision_curve, recall_curve, thresholds)\n",
    "average_precision = average_precision_score(y_test.ravel(), y_pred.ravel())\n",
    "print(average_precision)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(recall_plot, precision_plot, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
