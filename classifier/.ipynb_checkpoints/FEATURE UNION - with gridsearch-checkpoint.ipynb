{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Properties\n",
    "py_file = \"LinearSCVResults.py\"\n",
    "date_file = \"data/dataset-4412-cleaned.csv\"\n",
    "start_time = time.time()\n",
    "testd_size = 0.35\n",
    "sarcastic_tweets = []\n",
    "normal_tweet = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweetID     0\n",
      "tweet       0\n",
      "target     10\n",
      "dtype: int64\n",
      "tweetID    0\n",
      "tweet      0\n",
      "target     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read Data Set\n",
    "df = pd.read_csv(date_file, delimiter='|', encoding=\"utf-8\", quotechar='\"', header=None, names=['tweetID','tweet', 'target'])\n",
    "df = df.dropna()\n",
    "df.head()\n",
    "df[\"target\"] = df[\"target\"].convert_objects(convert_numeric=True)\n",
    "print(df.isnull().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"target\"] = df[\"target\"].astype(int)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['f1'] = pd.Series(np.random.uniform(0,15,len(df)), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(df[['tweet','f1']]\n",
    ", df['target'], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=[]):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        #print(self.transform(X))\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        #print(X[self.columns])\n",
    "        return X[self.columns]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        #print(self)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Reshaper(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        #print(X.reshape((len(X), 1)))\n",
    "        return X.reshape((len(X), 1))\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        #print(self.transform(X))\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        #print(self)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## WORKING!!!!\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "pipe = Pipeline([\n",
    "    ('features', FeatureUnion\n",
    "     ([      \n",
    "# F1 extract and process\n",
    "        ('f1', Pipeline([\n",
    "            ('extract', ColumnExtractor('f1')),\n",
    "            ('to_dense', Reshaper())\n",
    "        ]))\n",
    "        ,('tweet', Pipeline([\n",
    "            ('extract', ColumnExtractor('tweet')),\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ]))\n",
    "                    \n",
    "                ])),\n",
    "        ('clf', MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'features__tweet__vect__ngram_range': ((1, 3), (2, 3), (1, 2)), \n",
    "              'features__tweet__vect__max_df': (0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7),\n",
    "#               'vect__min_df': (0.1,0.25,0.5,0.75, 1.0),\n",
    "              'features__tweet__tfidf__use_idf': (True, False),\n",
    "              'features__tweet__tfidf__sublinear_tf': (True, False),\n",
    "              'clf__alpha': (0.00001, 0.000001),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipe,parameters,n_jobs=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params =grid_search.best_estimator_.get_params(deep=True)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_params[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_grid = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, f1_score, precision_recall_curve,average_precision_score\n",
    "\n",
    "recall = recall_score(y_test, y_pred_grid)\n",
    "precision = precision_score(y_test, y_pred_grid)\n",
    "confusion = confusion_matrix(y_test, y_pred_grid, labels=None)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: \"+str(precision))\n",
    "print(\"Recall: \"+str(recall))\n",
    "print(\"\\nConfusion matrix: \")\n",
    "print(confusion)\n",
    "print(\"\\nF1 score: \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
